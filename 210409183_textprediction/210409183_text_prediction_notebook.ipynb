{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "AmtDciwH2_0j",
      "metadata": {
        "id": "AmtDciwH2_0j"
      },
      "source": [
        "Befor running the script pass the location of the .txt file to source_text parameter.   \n",
        "Run the code and finally in the testing area, input the sentence for which the model predicts the output.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "16tVQ8XJ3ICg",
      "metadata": {
        "id": "16tVQ8XJ3ICg"
      },
      "outputs": [],
      "source": [
        "source_text='/content/gdrive/MyDrive/science_fiction/internet_archive_scifi_v3.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0cG0WaGgBaq7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cG0WaGgBaq7",
        "outputId": "7dd1ac1a-4b89-48ab-bd21-344d0b9b94f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "82e16ca5-1d5d-4826-bc33-4487a68569e3",
      "metadata": {
        "id": "82e16ca5-1d5d-4826-bc33-4487a68569e3"
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from numpy import array\n",
        "from pickle import dump\n",
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.utils import pad_sequences\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6245d02f-9d94-4e9e-b9bf-30b1d1b754e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6245d02f-9d94-4e9e-b9bf-30b1d1b754e1",
        "outputId": "7e4218d5-d965-4cb5-9c4e-252d136f3fcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MARCH # All Stories New and Complete Publisher Editor IF is published bi-monthly by Quinn Publishing\n"
          ]
        }
      ],
      "source": [
        "# Loading text into memory\n",
        "file= open(source_text, 'r')\n",
        "data= file.read()\n",
        "file.close()\n",
        "print(data[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "pBVf1opB6JD-",
      "metadata": {
        "id": "pBVf1opB6JD-"
      },
      "outputs": [],
      "source": [
        "data=data[5000:1000000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2f18fa49-d920-4995-821d-28cb3cf42482",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f18fa49-d920-4995-821d-28cb3cf42482",
        "outputId": "230b8b2d-65c1-4a9d-9e5d-6d280e14357f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "177240\n",
            "15101\n"
          ]
        }
      ],
      "source": [
        "# Cleaning text\n",
        "def clean_data(data):\n",
        "    # replace '--' with a space\n",
        "    data= data.replace('--', ' ')\n",
        "    #splitting into tokens by space\n",
        "    words= data.split()\n",
        "    #removing punctuations\n",
        "    words= [word.translate(str.maketrans('', '', string.punctuation)) for word in words]\n",
        "    #removing non-aplhabetic tokens\n",
        "    words= [word for word in words if word.isalpha()]\n",
        "    # lower-case\n",
        "    tokens= [word.lower() for word in words]\n",
        "    return tokens\n",
        "\n",
        "tokens= clean_data(data)\n",
        "print(len(tokens))\n",
        "print(len(set(tokens)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0dbf54b7-d3ba-4494-b05c-371802c72af2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dbf54b7-d3ba-4494-b05c-371802c72af2",
        "outputId": "91c03220-124d-4e95-abe7-96aaa909cadd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "177229\n"
          ]
        }
      ],
      "source": [
        "# creating sequences from tokens\n",
        "length= 11 #length of sequence()\n",
        "sequences= list()\n",
        "for i in range(length, len(tokens)):\n",
        "    seq= tokens[i-length:i]\n",
        "    line= ' '.join(seq)\n",
        "    sequences.append(line)\n",
        "print(len(sequences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "37VOztzg2B51",
      "metadata": {
        "id": "37VOztzg2B51"
      },
      "outputs": [],
      "source": [
        "!mkdir /data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "789e9bdd-add2-4974-ad0b-e0e90d5be26c",
      "metadata": {
        "id": "789e9bdd-add2-4974-ad0b-e0e90d5be26c"
      },
      "outputs": [],
      "source": [
        "# saving into file\n",
        "data = '\\n'.join(sequences)\n",
        "file = open('/data/scify_preprocessed.txt', 'w')\n",
        "file.write(data)\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7c4f5d8b-1325-4617-b88a-0f56da7795de",
      "metadata": {
        "id": "7c4f5d8b-1325-4617-b88a-0f56da7795de"
      },
      "outputs": [],
      "source": [
        "# loading scify_preprocessed.txt file\n",
        "file= open('/data/scify_preprocessed.txt', 'r')\n",
        "doc= file.read()\n",
        "file.close()\n",
        "lines= doc.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "CoKpmrU_5pLq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoKpmrU_5pLq",
        "outputId": "469460d4-453b-4b5b-9cc1-5a74e9b5db30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#cleaning the memory\n",
        "import gc\n",
        "del data\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "93a255b9-43fd-406e-b8ea-90ba52612fb4",
      "metadata": {
        "id": "93a255b9-43fd-406e-b8ea-90ba52612fb4"
      },
      "outputs": [],
      "source": [
        "# Encoding Sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "#padded_sequences = pad_sequences(sequences, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d86741e4-e272-407e-9a34-e5650609cd1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d86741e4-e272-407e-9a34-e5650609cd1c",
        "outputId": "79c6f75d-d549-4d38-bf44-3ffbee67c622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15101\n"
          ]
        }
      ],
      "source": [
        "# Size of vocabolary\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cdM68LREfMO8",
      "metadata": {
        "id": "cdM68LREfMO8"
      },
      "outputs": [],
      "source": [
        "# Separating into input, output sequences\n",
        "sequences = array(sequences)# converting to array\n",
        "x, y = sequences[:,:-1], sequences[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "99ce6882-20ac-47b3-ba6e-00b4232cf68a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99ce6882-20ac-47b3-ba6e-00b4232cf68a",
        "outputId": "77a8be4c-8d17-4c2f-d970-fe3cf73eb701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "# One-hot encoding output\n",
        "y = to_categorical(y, num_classes=vocab_size)#vocab_size)\n",
        "seq_length = x.shape[1]\n",
        "print(seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RdqL-gZzKcHk",
      "metadata": {
        "id": "RdqL-gZzKcHk"
      },
      "outputs": [],
      "source": [
        "#test code\n",
        "#vocab_size=10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a43c2d2-8264-41d1-b944-3b4a31988172",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a43c2d2-8264-41d1-b944-3b4a31988172",
        "outputId": "63daaf0f-3745-434d-c91c-a56b35f628ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 10)            151010    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10, 32)            5504      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                24832     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 15101)             1948029   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,141,855\n",
            "Trainable params: 2,141,855\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Builduing LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=seq_length))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k4SLpbS7BWIj",
      "metadata": {
        "id": "k4SLpbS7BWIj"
      },
      "outputs": [],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d3401c-f02a-4c94-8946-22f15aed93f6",
      "metadata": {
        "id": "04d3401c-f02a-4c94-8946-22f15aed93f6",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Compiling and fitting model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "history= model.fit(x, y, batch_size=200, epochs=400,callbacks=[callback],verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dathVgFmbg0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dathVgFmbg0",
        "outputId": "933d9fe9-04fa-4ebc-f256-88f5902f452a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1773/1773 [==============================] - 38s 17ms/step - loss: 3.3090 - accuracy: 0.2935\n",
            "Epoch 2/100\n",
            "1773/1773 [==============================] - 19s 11ms/step - loss: 3.2895 - accuracy: 0.2974\n",
            "Epoch 3/100\n",
            "1773/1773 [==============================] - 19s 11ms/step - loss: 3.2916 - accuracy: 0.2965\n",
            "Epoch 4/100\n",
            "1773/1773 [==============================] - 19s 11ms/step - loss: 3.2846 - accuracy: 0.2985\n",
            "Epoch 5/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2760 - accuracy: 0.2996\n",
            "Epoch 6/100\n",
            "1773/1773 [==============================] - 19s 11ms/step - loss: 3.2691 - accuracy: 0.3009\n",
            "Epoch 7/100\n",
            "1773/1773 [==============================] - 19s 10ms/step - loss: 3.2596 - accuracy: 0.3026\n",
            "Epoch 8/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2585 - accuracy: 0.3027\n",
            "Epoch 9/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2498 - accuracy: 0.3043\n",
            "Epoch 10/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2416 - accuracy: 0.3053\n",
            "Epoch 11/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2371 - accuracy: 0.3062\n",
            "Epoch 12/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2289 - accuracy: 0.3079\n",
            "Epoch 13/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2266 - accuracy: 0.3083\n",
            "Epoch 14/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2171 - accuracy: 0.3099\n",
            "Epoch 15/100\n",
            "1773/1773 [==============================] - 19s 10ms/step - loss: 3.2163 - accuracy: 0.3101\n",
            "Epoch 16/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2121 - accuracy: 0.3105\n",
            "Epoch 17/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.2057 - accuracy: 0.3107\n",
            "Epoch 18/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1982 - accuracy: 0.3124\n",
            "Epoch 19/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1945 - accuracy: 0.3122\n",
            "Epoch 20/100\n",
            "1773/1773 [==============================] - 19s 11ms/step - loss: 3.1911 - accuracy: 0.3135\n",
            "Epoch 21/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1874 - accuracy: 0.3137\n",
            "Epoch 22/100\n",
            "1773/1773 [==============================] - 19s 11ms/step - loss: 3.1822 - accuracy: 0.3141\n",
            "Epoch 23/100\n",
            "1773/1773 [==============================] - 20s 11ms/step - loss: 3.1794 - accuracy: 0.3151\n",
            "Epoch 24/100\n",
            "1773/1773 [==============================] - 19s 11ms/step - loss: 3.1713 - accuracy: 0.3163\n",
            "Epoch 25/100\n",
            "1773/1773 [==============================] - 20s 11ms/step - loss: 3.1659 - accuracy: 0.3191\n",
            "Epoch 26/100\n",
            "1773/1773 [==============================] - 20s 11ms/step - loss: 3.1628 - accuracy: 0.3180\n",
            "Epoch 27/100\n",
            "1773/1773 [==============================] - 20s 11ms/step - loss: 3.1594 - accuracy: 0.3182\n",
            "Epoch 28/100\n",
            "1773/1773 [==============================] - 20s 11ms/step - loss: 3.1583 - accuracy: 0.3176\n",
            "Epoch 29/100\n",
            "1773/1773 [==============================] - 19s 11ms/step - loss: 3.1526 - accuracy: 0.3197\n",
            "Epoch 30/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1494 - accuracy: 0.3202\n",
            "Epoch 31/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1391 - accuracy: 0.3212\n",
            "Epoch 32/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1375 - accuracy: 0.3219\n",
            "Epoch 33/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1351 - accuracy: 0.3225\n",
            "Epoch 34/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1358 - accuracy: 0.3218\n",
            "Epoch 35/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1333 - accuracy: 0.3230\n",
            "Epoch 36/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1188 - accuracy: 0.3252\n",
            "Epoch 37/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1256 - accuracy: 0.3228\n",
            "Epoch 38/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1150 - accuracy: 0.3256\n",
            "Epoch 39/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1115 - accuracy: 0.3273\n",
            "Epoch 40/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1124 - accuracy: 0.3264\n",
            "Epoch 41/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1077 - accuracy: 0.3262\n",
            "Epoch 42/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1022 - accuracy: 0.3281\n",
            "Epoch 43/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.1005 - accuracy: 0.3283\n",
            "Epoch 44/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0943 - accuracy: 0.3290\n",
            "Epoch 45/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0947 - accuracy: 0.3291\n",
            "Epoch 46/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0940 - accuracy: 0.3292\n",
            "Epoch 47/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0876 - accuracy: 0.3300\n",
            "Epoch 48/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0847 - accuracy: 0.3308\n",
            "Epoch 49/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0803 - accuracy: 0.3314\n",
            "Epoch 50/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0812 - accuracy: 0.3309\n",
            "Epoch 51/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0733 - accuracy: 0.3322\n",
            "Epoch 52/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0752 - accuracy: 0.3320\n",
            "Epoch 53/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0728 - accuracy: 0.3327\n",
            "Epoch 54/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0685 - accuracy: 0.3330\n",
            "Epoch 55/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0676 - accuracy: 0.3341\n",
            "Epoch 56/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0563 - accuracy: 0.3351\n",
            "Epoch 57/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0589 - accuracy: 0.3343\n",
            "Epoch 58/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0547 - accuracy: 0.3361\n",
            "Epoch 59/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0559 - accuracy: 0.3354\n",
            "Epoch 60/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0515 - accuracy: 0.3360\n",
            "Epoch 61/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0504 - accuracy: 0.3358\n",
            "Epoch 62/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0453 - accuracy: 0.3364\n",
            "Epoch 63/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0490 - accuracy: 0.3366\n",
            "Epoch 64/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0433 - accuracy: 0.3370\n",
            "Epoch 65/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0405 - accuracy: 0.3377\n",
            "Epoch 66/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0359 - accuracy: 0.3380\n",
            "Epoch 67/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0351 - accuracy: 0.3385\n",
            "Epoch 68/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0337 - accuracy: 0.3387\n",
            "Epoch 69/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0316 - accuracy: 0.3397\n",
            "Epoch 70/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0293 - accuracy: 0.3398\n",
            "Epoch 71/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0255 - accuracy: 0.3399\n",
            "Epoch 72/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0228 - accuracy: 0.3409\n",
            "Epoch 73/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0247 - accuracy: 0.3411\n",
            "Epoch 74/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0205 - accuracy: 0.3415\n",
            "Epoch 75/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0173 - accuracy: 0.3425\n",
            "Epoch 76/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0158 - accuracy: 0.3420\n",
            "Epoch 77/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0128 - accuracy: 0.3422\n",
            "Epoch 78/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0092 - accuracy: 0.3434\n",
            "Epoch 79/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0080 - accuracy: 0.3440\n",
            "Epoch 80/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0023 - accuracy: 0.3436\n",
            "Epoch 81/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0057 - accuracy: 0.3445\n",
            "Epoch 82/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9986 - accuracy: 0.3445\n",
            "Epoch 83/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9988 - accuracy: 0.3454\n",
            "Epoch 84/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 3.0024 - accuracy: 0.3449\n",
            "Epoch 85/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9967 - accuracy: 0.3455\n",
            "Epoch 86/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9952 - accuracy: 0.3450\n",
            "Epoch 87/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9933 - accuracy: 0.3457\n",
            "Epoch 88/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9898 - accuracy: 0.3461\n",
            "Epoch 89/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9944 - accuracy: 0.3451\n",
            "Epoch 90/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9863 - accuracy: 0.3463\n",
            "Epoch 91/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9822 - accuracy: 0.3481\n",
            "Epoch 92/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9836 - accuracy: 0.3484\n",
            "Epoch 93/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9812 - accuracy: 0.3483\n",
            "Epoch 94/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9793 - accuracy: 0.3488\n",
            "Epoch 95/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9766 - accuracy: 0.3480\n",
            "Epoch 96/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9767 - accuracy: 0.3487\n",
            "Epoch 97/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9749 - accuracy: 0.3496\n",
            "Epoch 98/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9694 - accuracy: 0.3497\n",
            "Epoch 99/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9697 - accuracy: 0.3495\n",
            "Epoch 100/100\n",
            "1773/1773 [==============================] - 18s 10ms/step - loss: 2.9710 - accuracy: 0.3502\n"
          ]
        }
      ],
      "source": [
        "#igone this part as it used for re training the already trained model bu the performance was not increasing\n",
        "history= model.fit(x, y, batch_size=100, epochs=100,callbacks=[callback],verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IVx4QzfQvjUN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVx4QzfQvjUN",
        "outputId": "abf64e33-a8fc-4ba2-84bf-377ff1754ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1182/1182 [==============================] - 32s 23ms/step - loss: 2.8866 - accuracy: 0.3664\n",
            "Epoch 2/150\n",
            "1182/1182 [==============================] - 15s 13ms/step - loss: 2.8860 - accuracy: 0.3655\n",
            "Epoch 3/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8773 - accuracy: 0.3678\n",
            "Epoch 4/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8745 - accuracy: 0.3685\n",
            "Epoch 5/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8758 - accuracy: 0.3680\n",
            "Epoch 6/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8768 - accuracy: 0.3671\n",
            "Epoch 7/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8656 - accuracy: 0.3697\n",
            "Epoch 8/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8680 - accuracy: 0.3700\n",
            "Epoch 9/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8716 - accuracy: 0.3684\n",
            "Epoch 10/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8665 - accuracy: 0.3705\n",
            "Epoch 11/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.8642 - accuracy: 0.3701\n",
            "Epoch 12/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8645 - accuracy: 0.3696\n",
            "Epoch 13/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.8653 - accuracy: 0.3702\n",
            "Epoch 14/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.8541 - accuracy: 0.3713\n",
            "Epoch 15/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8601 - accuracy: 0.3705\n",
            "Epoch 16/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8611 - accuracy: 0.3711\n",
            "Epoch 17/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8528 - accuracy: 0.3733\n",
            "Epoch 18/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8484 - accuracy: 0.3733\n",
            "Epoch 19/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8521 - accuracy: 0.3723\n",
            "Epoch 20/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8510 - accuracy: 0.3726\n",
            "Epoch 21/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8476 - accuracy: 0.3733\n",
            "Epoch 22/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8478 - accuracy: 0.3727\n",
            "Epoch 23/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8429 - accuracy: 0.3739\n",
            "Epoch 24/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8417 - accuracy: 0.3735\n",
            "Epoch 25/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8493 - accuracy: 0.3722\n",
            "Epoch 26/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8420 - accuracy: 0.3740\n",
            "Epoch 27/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8410 - accuracy: 0.3738\n",
            "Epoch 28/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8355 - accuracy: 0.3752\n",
            "Epoch 29/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.8353 - accuracy: 0.3752\n",
            "Epoch 30/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8357 - accuracy: 0.3755\n",
            "Epoch 31/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8382 - accuracy: 0.3755\n",
            "Epoch 32/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8300 - accuracy: 0.3762\n",
            "Epoch 33/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8256 - accuracy: 0.3764\n",
            "Epoch 34/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8311 - accuracy: 0.3756\n",
            "Epoch 35/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8281 - accuracy: 0.3759\n",
            "Epoch 36/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8275 - accuracy: 0.3759\n",
            "Epoch 37/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8278 - accuracy: 0.3770\n",
            "Epoch 38/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8313 - accuracy: 0.3762\n",
            "Epoch 39/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8227 - accuracy: 0.3768\n",
            "Epoch 40/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8218 - accuracy: 0.3773\n",
            "Epoch 41/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8208 - accuracy: 0.3767\n",
            "Epoch 42/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8239 - accuracy: 0.3770\n",
            "Epoch 43/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8174 - accuracy: 0.3782\n",
            "Epoch 44/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8193 - accuracy: 0.3788\n",
            "Epoch 45/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8199 - accuracy: 0.3780\n",
            "Epoch 46/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8166 - accuracy: 0.3781\n",
            "Epoch 47/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8233 - accuracy: 0.3760\n",
            "Epoch 48/150\n",
            "1182/1182 [==============================] - 15s 12ms/step - loss: 2.8115 - accuracy: 0.3789\n",
            "Epoch 49/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8050 - accuracy: 0.3806\n",
            "Epoch 50/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8138 - accuracy: 0.3788\n",
            "Epoch 51/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8069 - accuracy: 0.3793\n",
            "Epoch 52/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8049 - accuracy: 0.3806\n",
            "Epoch 53/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8087 - accuracy: 0.3801\n",
            "Epoch 54/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8077 - accuracy: 0.3798\n",
            "Epoch 55/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8042 - accuracy: 0.3803\n",
            "Epoch 56/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7968 - accuracy: 0.3811\n",
            "Epoch 57/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7996 - accuracy: 0.3812\n",
            "Epoch 58/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8016 - accuracy: 0.3814\n",
            "Epoch 59/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.8066 - accuracy: 0.3798\n",
            "Epoch 60/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.8053 - accuracy: 0.3803\n",
            "Epoch 61/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7962 - accuracy: 0.3818\n",
            "Epoch 62/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7909 - accuracy: 0.3831\n",
            "Epoch 63/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7977 - accuracy: 0.3802\n",
            "Epoch 64/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7970 - accuracy: 0.3816\n",
            "Epoch 65/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7975 - accuracy: 0.3813\n",
            "Epoch 66/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7872 - accuracy: 0.3830\n",
            "Epoch 67/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7926 - accuracy: 0.3823\n",
            "Epoch 68/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7930 - accuracy: 0.3817\n",
            "Epoch 69/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7999 - accuracy: 0.3801\n",
            "Epoch 70/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.7810 - accuracy: 0.3850\n",
            "Epoch 71/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7832 - accuracy: 0.3844\n",
            "Epoch 72/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7912 - accuracy: 0.3826\n",
            "Epoch 73/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7883 - accuracy: 0.3826\n",
            "Epoch 74/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7792 - accuracy: 0.3852\n",
            "Epoch 75/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7832 - accuracy: 0.3846\n",
            "Epoch 76/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7819 - accuracy: 0.3842\n",
            "Epoch 77/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7807 - accuracy: 0.3844\n",
            "Epoch 78/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7784 - accuracy: 0.3849\n",
            "Epoch 79/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7791 - accuracy: 0.3845\n",
            "Epoch 80/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7814 - accuracy: 0.3841\n",
            "Epoch 81/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7764 - accuracy: 0.3855\n",
            "Epoch 82/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7694 - accuracy: 0.3863\n",
            "Epoch 83/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7741 - accuracy: 0.3851\n",
            "Epoch 84/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7706 - accuracy: 0.3856\n",
            "Epoch 85/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7697 - accuracy: 0.3860\n",
            "Epoch 86/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7831 - accuracy: 0.3832\n",
            "Epoch 87/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7678 - accuracy: 0.3868\n",
            "Epoch 88/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7688 - accuracy: 0.3871\n",
            "Epoch 89/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7699 - accuracy: 0.3855\n",
            "Epoch 90/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7683 - accuracy: 0.3877\n",
            "Epoch 91/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7643 - accuracy: 0.3874\n",
            "Epoch 92/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7616 - accuracy: 0.3870\n",
            "Epoch 93/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7596 - accuracy: 0.3874\n",
            "Epoch 94/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7599 - accuracy: 0.3879\n",
            "Epoch 95/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7614 - accuracy: 0.3878\n",
            "Epoch 96/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7595 - accuracy: 0.3886\n",
            "Epoch 97/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7515 - accuracy: 0.3891\n",
            "Epoch 98/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7572 - accuracy: 0.3887\n",
            "Epoch 99/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7530 - accuracy: 0.3892\n",
            "Epoch 100/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7602 - accuracy: 0.3883\n",
            "Epoch 101/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7548 - accuracy: 0.3878\n",
            "Epoch 102/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7549 - accuracy: 0.3896\n",
            "Epoch 103/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7471 - accuracy: 0.3904\n",
            "Epoch 104/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7526 - accuracy: 0.3889\n",
            "Epoch 105/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7503 - accuracy: 0.3896\n",
            "Epoch 106/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7496 - accuracy: 0.3901\n",
            "Epoch 107/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7506 - accuracy: 0.3906\n",
            "Epoch 108/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7483 - accuracy: 0.3895\n",
            "Epoch 109/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7410 - accuracy: 0.3915\n",
            "Epoch 110/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7414 - accuracy: 0.3915\n",
            "Epoch 111/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7476 - accuracy: 0.3901\n",
            "Epoch 112/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7372 - accuracy: 0.3926\n",
            "Epoch 113/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7517 - accuracy: 0.3895\n",
            "Epoch 114/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7381 - accuracy: 0.3923\n",
            "Epoch 115/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7386 - accuracy: 0.3920\n",
            "Epoch 116/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7441 - accuracy: 0.3911\n",
            "Epoch 117/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7370 - accuracy: 0.3926\n",
            "Epoch 118/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7369 - accuracy: 0.3932\n",
            "Epoch 119/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7410 - accuracy: 0.3916\n",
            "Epoch 120/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7331 - accuracy: 0.3927\n",
            "Epoch 121/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7381 - accuracy: 0.3921\n",
            "Epoch 122/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7265 - accuracy: 0.3948\n",
            "Epoch 123/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7291 - accuracy: 0.3937\n",
            "Epoch 124/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7363 - accuracy: 0.3916\n",
            "Epoch 125/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7347 - accuracy: 0.3924\n",
            "Epoch 126/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7283 - accuracy: 0.3940\n",
            "Epoch 127/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7313 - accuracy: 0.3934\n",
            "Epoch 128/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7263 - accuracy: 0.3940\n",
            "Epoch 129/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7233 - accuracy: 0.3951\n",
            "Epoch 130/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7257 - accuracy: 0.3935\n",
            "Epoch 131/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7327 - accuracy: 0.3942\n",
            "Epoch 132/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7332 - accuracy: 0.3928\n",
            "Epoch 133/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.7202 - accuracy: 0.3955\n",
            "Epoch 134/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.7205 - accuracy: 0.3947\n",
            "Epoch 135/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7301 - accuracy: 0.3933\n",
            "Epoch 136/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7198 - accuracy: 0.3958\n",
            "Epoch 137/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7273 - accuracy: 0.3934\n",
            "Epoch 138/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7230 - accuracy: 0.3950\n",
            "Epoch 139/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7186 - accuracy: 0.3955\n",
            "Epoch 140/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7156 - accuracy: 0.3963\n",
            "Epoch 141/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7210 - accuracy: 0.3955\n",
            "Epoch 142/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.7102 - accuracy: 0.3971\n",
            "Epoch 143/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.7211 - accuracy: 0.3958\n",
            "Epoch 144/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.7163 - accuracy: 0.3963\n",
            "Epoch 145/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7131 - accuracy: 0.3973\n",
            "Epoch 146/150\n",
            "1182/1182 [==============================] - 14s 11ms/step - loss: 2.7134 - accuracy: 0.3967\n",
            "Epoch 147/150\n",
            "1182/1182 [==============================] - 14s 12ms/step - loss: 2.7184 - accuracy: 0.3955\n",
            "Epoch 148/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.7091 - accuracy: 0.3979\n",
            "Epoch 149/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.7193 - accuracy: 0.3957\n",
            "Epoch 150/150\n",
            "1182/1182 [==============================] - 13s 11ms/step - loss: 2.7131 - accuracy: 0.3969\n"
          ]
        }
      ],
      "source": [
        "#igone this part as it used for re training the already trained model bu the performance was not increasing\n",
        "history= model.fit(x, y, batch_size=150, epochs=150,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g9_K0Ey--uLk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9_K0Ey--uLk",
        "outputId": "7187b9bb-23f8-4d5c-d37a-43b73f7c387c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "887/887 [==============================] - 31s 29ms/step - loss: 7.1738 - accuracy: 0.0582\n",
            "Epoch 2/400\n",
            "887/887 [==============================] - 13s 14ms/step - loss: 6.8411 - accuracy: 0.0590\n",
            "Epoch 3/400\n",
            "887/887 [==============================] - 11s 13ms/step - loss: 6.5955 - accuracy: 0.0692\n",
            "Epoch 4/400\n",
            "887/887 [==============================] - 11s 13ms/step - loss: 6.3877 - accuracy: 0.0769\n",
            "Epoch 5/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 6.2277 - accuracy: 0.0837\n",
            "Epoch 6/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 6.0838 - accuracy: 0.0905\n",
            "Epoch 7/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 5.9448 - accuracy: 0.0975\n",
            "Epoch 8/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 5.8190 - accuracy: 0.1032\n",
            "Epoch 9/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 5.7039 - accuracy: 0.1078\n",
            "Epoch 10/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 5.5907 - accuracy: 0.1122\n",
            "Epoch 11/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 5.4778 - accuracy: 0.1157\n",
            "Epoch 12/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 5.3666 - accuracy: 0.1192\n",
            "Epoch 13/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 5.2586 - accuracy: 0.1222\n",
            "Epoch 14/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 5.1524 - accuracy: 0.1248\n",
            "Epoch 15/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 5.0486 - accuracy: 0.1273\n",
            "Epoch 16/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.9473 - accuracy: 0.1305\n",
            "Epoch 17/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.8481 - accuracy: 0.1345\n",
            "Epoch 18/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.7553 - accuracy: 0.1389\n",
            "Epoch 19/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.6667 - accuracy: 0.1445\n",
            "Epoch 20/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.5832 - accuracy: 0.1514\n",
            "Epoch 21/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.5110 - accuracy: 0.1567\n",
            "Epoch 22/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.4390 - accuracy: 0.1635\n",
            "Epoch 23/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 4.3792 - accuracy: 0.1691\n",
            "Epoch 24/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.3207 - accuracy: 0.1759\n",
            "Epoch 25/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.2672 - accuracy: 0.1805\n",
            "Epoch 26/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.2190 - accuracy: 0.1852\n",
            "Epoch 27/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.1729 - accuracy: 0.1901\n",
            "Epoch 28/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.1309 - accuracy: 0.1948\n",
            "Epoch 29/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.0871 - accuracy: 0.1997\n",
            "Epoch 30/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.0508 - accuracy: 0.2042\n",
            "Epoch 31/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 4.0164 - accuracy: 0.2079\n",
            "Epoch 32/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.9817 - accuracy: 0.2113\n",
            "Epoch 33/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.9452 - accuracy: 0.2162\n",
            "Epoch 34/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.9155 - accuracy: 0.2197\n",
            "Epoch 35/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.8879 - accuracy: 0.2234\n",
            "Epoch 36/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.8578 - accuracy: 0.2267\n",
            "Epoch 37/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.8302 - accuracy: 0.2300\n",
            "Epoch 38/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.8021 - accuracy: 0.2344\n",
            "Epoch 39/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.7789 - accuracy: 0.2372\n",
            "Epoch 40/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.7539 - accuracy: 0.2408\n",
            "Epoch 41/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.7318 - accuracy: 0.2428\n",
            "Epoch 42/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.7082 - accuracy: 0.2461\n",
            "Epoch 43/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.6888 - accuracy: 0.2484\n",
            "Epoch 44/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.6647 - accuracy: 0.2513\n",
            "Epoch 45/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.6477 - accuracy: 0.2545\n",
            "Epoch 46/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.6227 - accuracy: 0.2582\n",
            "Epoch 47/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.6080 - accuracy: 0.2592\n",
            "Epoch 48/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.5933 - accuracy: 0.2617\n",
            "Epoch 49/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.5710 - accuracy: 0.2648\n",
            "Epoch 50/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.5556 - accuracy: 0.2669\n",
            "Epoch 51/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.5379 - accuracy: 0.2692\n",
            "Epoch 52/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.5196 - accuracy: 0.2719\n",
            "Epoch 53/400\n",
            "887/887 [==============================] - 11s 13ms/step - loss: 3.5087 - accuracy: 0.2731\n",
            "Epoch 54/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.4905 - accuracy: 0.2760\n",
            "Epoch 55/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.4770 - accuracy: 0.2785\n",
            "Epoch 56/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.4604 - accuracy: 0.2810\n",
            "Epoch 57/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.4452 - accuracy: 0.2819\n",
            "Epoch 58/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.4321 - accuracy: 0.2850\n",
            "Epoch 59/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.4177 - accuracy: 0.2863\n",
            "Epoch 60/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.4070 - accuracy: 0.2885\n",
            "Epoch 61/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.3915 - accuracy: 0.2896\n",
            "Epoch 62/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.3840 - accuracy: 0.2918\n",
            "Epoch 63/400\n",
            "887/887 [==============================] - 11s 13ms/step - loss: 3.3715 - accuracy: 0.2935\n",
            "Epoch 64/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.3535 - accuracy: 0.2954\n",
            "Epoch 65/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.3437 - accuracy: 0.2973\n",
            "Epoch 66/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.3343 - accuracy: 0.2987\n",
            "Epoch 67/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.3207 - accuracy: 0.3007\n",
            "Epoch 68/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.3123 - accuracy: 0.3023\n",
            "Epoch 69/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.3009 - accuracy: 0.3043\n",
            "Epoch 70/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.2922 - accuracy: 0.3062\n",
            "Epoch 71/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.2786 - accuracy: 0.3072\n",
            "Epoch 72/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.2702 - accuracy: 0.3085\n",
            "Epoch 73/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.2602 - accuracy: 0.3098\n",
            "Epoch 74/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.2485 - accuracy: 0.3120\n",
            "Epoch 75/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.2384 - accuracy: 0.3128\n",
            "Epoch 76/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.2318 - accuracy: 0.3146\n",
            "Epoch 77/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.2226 - accuracy: 0.3160\n",
            "Epoch 78/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.2115 - accuracy: 0.3176\n",
            "Epoch 79/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.2019 - accuracy: 0.3185\n",
            "Epoch 80/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1909 - accuracy: 0.3202\n",
            "Epoch 81/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 3.1869 - accuracy: 0.3205\n",
            "Epoch 82/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1736 - accuracy: 0.3231\n",
            "Epoch 83/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1676 - accuracy: 0.3238\n",
            "Epoch 84/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1562 - accuracy: 0.3246\n",
            "Epoch 85/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1478 - accuracy: 0.3274\n",
            "Epoch 86/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1391 - accuracy: 0.3282\n",
            "Epoch 87/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1322 - accuracy: 0.3288\n",
            "Epoch 88/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1255 - accuracy: 0.3307\n",
            "Epoch 89/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1178 - accuracy: 0.3327\n",
            "Epoch 90/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1075 - accuracy: 0.3328\n",
            "Epoch 91/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.1038 - accuracy: 0.3338\n",
            "Epoch 92/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0927 - accuracy: 0.3355\n",
            "Epoch 93/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0836 - accuracy: 0.3377\n",
            "Epoch 94/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0744 - accuracy: 0.3380\n",
            "Epoch 95/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0711 - accuracy: 0.3382\n",
            "Epoch 96/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0645 - accuracy: 0.3407\n",
            "Epoch 97/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0563 - accuracy: 0.3408\n",
            "Epoch 98/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0486 - accuracy: 0.3414\n",
            "Epoch 99/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0422 - accuracy: 0.3426\n",
            "Epoch 100/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0373 - accuracy: 0.3440\n",
            "Epoch 101/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0286 - accuracy: 0.3453\n",
            "Epoch 102/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0226 - accuracy: 0.3462\n",
            "Epoch 103/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0182 - accuracy: 0.3467\n",
            "Epoch 104/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0113 - accuracy: 0.3485\n",
            "Epoch 105/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 3.0039 - accuracy: 0.3500\n",
            "Epoch 106/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.9994 - accuracy: 0.3505\n",
            "Epoch 107/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.9922 - accuracy: 0.3516\n",
            "Epoch 108/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.9823 - accuracy: 0.3531\n",
            "Epoch 109/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.9833 - accuracy: 0.3518\n",
            "Epoch 110/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.9754 - accuracy: 0.3539\n",
            "Epoch 111/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9672 - accuracy: 0.3559\n",
            "Epoch 112/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9629 - accuracy: 0.3555\n",
            "Epoch 113/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9534 - accuracy: 0.3573\n",
            "Epoch 114/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9477 - accuracy: 0.3580\n",
            "Epoch 115/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9445 - accuracy: 0.3592\n",
            "Epoch 116/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9406 - accuracy: 0.3588\n",
            "Epoch 117/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9331 - accuracy: 0.3605\n",
            "Epoch 118/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9272 - accuracy: 0.3620\n",
            "Epoch 119/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9240 - accuracy: 0.3615\n",
            "Epoch 120/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9164 - accuracy: 0.3634\n",
            "Epoch 121/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9116 - accuracy: 0.3645\n",
            "Epoch 122/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9068 - accuracy: 0.3646\n",
            "Epoch 123/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.9047 - accuracy: 0.3651\n",
            "Epoch 124/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8995 - accuracy: 0.3659\n",
            "Epoch 125/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8869 - accuracy: 0.3680\n",
            "Epoch 126/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8934 - accuracy: 0.3673\n",
            "Epoch 127/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8851 - accuracy: 0.3686\n",
            "Epoch 128/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8782 - accuracy: 0.3695\n",
            "Epoch 129/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8765 - accuracy: 0.3692\n",
            "Epoch 130/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8671 - accuracy: 0.3714\n",
            "Epoch 131/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8680 - accuracy: 0.3717\n",
            "Epoch 132/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8586 - accuracy: 0.3723\n",
            "Epoch 133/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8572 - accuracy: 0.3732\n",
            "Epoch 134/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8474 - accuracy: 0.3749\n",
            "Epoch 135/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8472 - accuracy: 0.3745\n",
            "Epoch 136/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8420 - accuracy: 0.3759\n",
            "Epoch 137/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8414 - accuracy: 0.3761\n",
            "Epoch 138/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8326 - accuracy: 0.3766\n",
            "Epoch 139/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8316 - accuracy: 0.3774\n",
            "Epoch 140/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8214 - accuracy: 0.3794\n",
            "Epoch 141/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8200 - accuracy: 0.3786\n",
            "Epoch 142/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8235 - accuracy: 0.3786\n",
            "Epoch 143/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8155 - accuracy: 0.3799\n",
            "Epoch 144/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8102 - accuracy: 0.3816\n",
            "Epoch 145/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8062 - accuracy: 0.3818\n",
            "Epoch 146/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8004 - accuracy: 0.3818\n",
            "Epoch 147/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.8002 - accuracy: 0.3822\n",
            "Epoch 148/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7960 - accuracy: 0.3836\n",
            "Epoch 149/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7900 - accuracy: 0.3841\n",
            "Epoch 150/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7875 - accuracy: 0.3854\n",
            "Epoch 151/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7833 - accuracy: 0.3857\n",
            "Epoch 152/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7822 - accuracy: 0.3858\n",
            "Epoch 153/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7744 - accuracy: 0.3868\n",
            "Epoch 154/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7698 - accuracy: 0.3877\n",
            "Epoch 155/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7659 - accuracy: 0.3877\n",
            "Epoch 156/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7638 - accuracy: 0.3886\n",
            "Epoch 157/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7625 - accuracy: 0.3880\n",
            "Epoch 158/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7637 - accuracy: 0.3878\n",
            "Epoch 159/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7527 - accuracy: 0.3906\n",
            "Epoch 160/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7531 - accuracy: 0.3906\n",
            "Epoch 161/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7464 - accuracy: 0.3912\n",
            "Epoch 162/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7421 - accuracy: 0.3927\n",
            "Epoch 163/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7379 - accuracy: 0.3936\n",
            "Epoch 164/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7410 - accuracy: 0.3925\n",
            "Epoch 165/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7324 - accuracy: 0.3944\n",
            "Epoch 166/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7310 - accuracy: 0.3941\n",
            "Epoch 167/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7205 - accuracy: 0.3956\n",
            "Epoch 168/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7214 - accuracy: 0.3956\n",
            "Epoch 169/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7233 - accuracy: 0.3950\n",
            "Epoch 170/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7196 - accuracy: 0.3965\n",
            "Epoch 171/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7123 - accuracy: 0.3974\n",
            "Epoch 172/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7027 - accuracy: 0.3995\n",
            "Epoch 173/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7063 - accuracy: 0.3972\n",
            "Epoch 174/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.7120 - accuracy: 0.3967\n",
            "Epoch 175/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6987 - accuracy: 0.3996\n",
            "Epoch 176/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6893 - accuracy: 0.4019\n",
            "Epoch 177/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6943 - accuracy: 0.4008\n",
            "Epoch 178/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6938 - accuracy: 0.3996\n",
            "Epoch 179/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6876 - accuracy: 0.4013\n",
            "Epoch 180/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6808 - accuracy: 0.4017\n",
            "Epoch 181/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6810 - accuracy: 0.4025\n",
            "Epoch 182/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6769 - accuracy: 0.4033\n",
            "Epoch 183/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6774 - accuracy: 0.4032\n",
            "Epoch 184/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6710 - accuracy: 0.4043\n",
            "Epoch 185/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6692 - accuracy: 0.4047\n",
            "Epoch 186/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6656 - accuracy: 0.4045\n",
            "Epoch 187/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6651 - accuracy: 0.4045\n",
            "Epoch 188/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6637 - accuracy: 0.4052\n",
            "Epoch 189/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6568 - accuracy: 0.4059\n",
            "Epoch 190/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6551 - accuracy: 0.4072\n",
            "Epoch 191/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6456 - accuracy: 0.4093\n",
            "Epoch 192/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6514 - accuracy: 0.4065\n",
            "Epoch 193/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6475 - accuracy: 0.4086\n",
            "Epoch 194/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6442 - accuracy: 0.4084\n",
            "Epoch 195/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6406 - accuracy: 0.4088\n",
            "Epoch 196/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6324 - accuracy: 0.4113\n",
            "Epoch 197/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6367 - accuracy: 0.4098\n",
            "Epoch 198/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6355 - accuracy: 0.4096\n",
            "Epoch 199/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.6323 - accuracy: 0.4108\n",
            "Epoch 200/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6263 - accuracy: 0.4124\n",
            "Epoch 201/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6286 - accuracy: 0.4115\n",
            "Epoch 202/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6232 - accuracy: 0.4122\n",
            "Epoch 203/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6165 - accuracy: 0.4138\n",
            "Epoch 204/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6183 - accuracy: 0.4129\n",
            "Epoch 205/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6209 - accuracy: 0.4131\n",
            "Epoch 206/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6147 - accuracy: 0.4142\n",
            "Epoch 207/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6116 - accuracy: 0.4147\n",
            "Epoch 208/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6056 - accuracy: 0.4158\n",
            "Epoch 209/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6053 - accuracy: 0.4149\n",
            "Epoch 210/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.6004 - accuracy: 0.4157\n",
            "Epoch 211/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5985 - accuracy: 0.4162\n",
            "Epoch 212/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5998 - accuracy: 0.4168\n",
            "Epoch 213/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5932 - accuracy: 0.4167\n",
            "Epoch 214/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5895 - accuracy: 0.4177\n",
            "Epoch 215/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5924 - accuracy: 0.4173\n",
            "Epoch 216/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5897 - accuracy: 0.4174\n",
            "Epoch 217/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5892 - accuracy: 0.4179\n",
            "Epoch 218/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5885 - accuracy: 0.4172\n",
            "Epoch 219/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5826 - accuracy: 0.4188\n",
            "Epoch 220/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5806 - accuracy: 0.4201\n",
            "Epoch 221/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5757 - accuracy: 0.4202\n",
            "Epoch 222/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5666 - accuracy: 0.4229\n",
            "Epoch 223/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5828 - accuracy: 0.4194\n",
            "Epoch 224/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5667 - accuracy: 0.4222\n",
            "Epoch 225/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5675 - accuracy: 0.4220\n",
            "Epoch 226/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5671 - accuracy: 0.4225\n",
            "Epoch 227/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5645 - accuracy: 0.4234\n",
            "Epoch 228/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5676 - accuracy: 0.4217\n",
            "Epoch 229/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5594 - accuracy: 0.4236\n",
            "Epoch 230/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5553 - accuracy: 0.4244\n",
            "Epoch 231/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5541 - accuracy: 0.4244\n",
            "Epoch 232/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5591 - accuracy: 0.4229\n",
            "Epoch 233/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5620 - accuracy: 0.4227\n",
            "Epoch 234/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5422 - accuracy: 0.4260\n",
            "Epoch 235/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5455 - accuracy: 0.4256\n",
            "Epoch 236/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5455 - accuracy: 0.4267\n",
            "Epoch 237/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5397 - accuracy: 0.4268\n",
            "Epoch 238/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5445 - accuracy: 0.4264\n",
            "Epoch 239/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5433 - accuracy: 0.4258\n",
            "Epoch 240/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5398 - accuracy: 0.4260\n",
            "Epoch 241/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5309 - accuracy: 0.4298\n",
            "Epoch 242/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5317 - accuracy: 0.4280\n",
            "Epoch 243/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5374 - accuracy: 0.4268\n",
            "Epoch 244/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5340 - accuracy: 0.4275\n",
            "Epoch 245/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5266 - accuracy: 0.4283\n",
            "Epoch 246/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5261 - accuracy: 0.4302\n",
            "Epoch 247/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5198 - accuracy: 0.4306\n",
            "Epoch 248/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5226 - accuracy: 0.4295\n",
            "Epoch 249/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5241 - accuracy: 0.4300\n",
            "Epoch 250/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5129 - accuracy: 0.4327\n",
            "Epoch 251/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5173 - accuracy: 0.4302\n",
            "Epoch 252/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5200 - accuracy: 0.4296\n",
            "Epoch 253/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5109 - accuracy: 0.4326\n",
            "Epoch 254/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5128 - accuracy: 0.4326\n",
            "Epoch 255/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5088 - accuracy: 0.4324\n",
            "Epoch 256/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5113 - accuracy: 0.4318\n",
            "Epoch 257/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5008 - accuracy: 0.4342\n",
            "Epoch 258/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5072 - accuracy: 0.4323\n",
            "Epoch 259/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.5018 - accuracy: 0.4337\n",
            "Epoch 260/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4981 - accuracy: 0.4345\n",
            "Epoch 261/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4999 - accuracy: 0.4339\n",
            "Epoch 262/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4992 - accuracy: 0.4338\n",
            "Epoch 263/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4940 - accuracy: 0.4352\n",
            "Epoch 264/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4904 - accuracy: 0.4355\n",
            "Epoch 265/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4912 - accuracy: 0.4360\n",
            "Epoch 266/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4920 - accuracy: 0.4354\n",
            "Epoch 267/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4888 - accuracy: 0.4352\n",
            "Epoch 268/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4861 - accuracy: 0.4363\n",
            "Epoch 269/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4889 - accuracy: 0.4359\n",
            "Epoch 270/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4842 - accuracy: 0.4365\n",
            "Epoch 271/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4846 - accuracy: 0.4358\n",
            "Epoch 272/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4782 - accuracy: 0.4383\n",
            "Epoch 273/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4829 - accuracy: 0.4364\n",
            "Epoch 274/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4769 - accuracy: 0.4379\n",
            "Epoch 275/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4771 - accuracy: 0.4376\n",
            "Epoch 276/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4766 - accuracy: 0.4368\n",
            "Epoch 277/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4675 - accuracy: 0.4399\n",
            "Epoch 278/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4691 - accuracy: 0.4391\n",
            "Epoch 279/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4684 - accuracy: 0.4393\n",
            "Epoch 280/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4672 - accuracy: 0.4394\n",
            "Epoch 281/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4668 - accuracy: 0.4394\n",
            "Epoch 282/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4648 - accuracy: 0.4398\n",
            "Epoch 283/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4646 - accuracy: 0.4401\n",
            "Epoch 284/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4624 - accuracy: 0.4397\n",
            "Epoch 285/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4583 - accuracy: 0.4408\n",
            "Epoch 286/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4560 - accuracy: 0.4413\n",
            "Epoch 287/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4576 - accuracy: 0.4412\n",
            "Epoch 288/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4552 - accuracy: 0.4418\n",
            "Epoch 289/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4524 - accuracy: 0.4424\n",
            "Epoch 290/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4524 - accuracy: 0.4424\n",
            "Epoch 291/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4548 - accuracy: 0.4421\n",
            "Epoch 292/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4568 - accuracy: 0.4414\n",
            "Epoch 293/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4465 - accuracy: 0.4442\n",
            "Epoch 294/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4511 - accuracy: 0.4414\n",
            "Epoch 295/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4435 - accuracy: 0.4436\n",
            "Epoch 296/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4373 - accuracy: 0.4454\n",
            "Epoch 297/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4430 - accuracy: 0.4439\n",
            "Epoch 298/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4346 - accuracy: 0.4452\n",
            "Epoch 299/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4496 - accuracy: 0.4435\n",
            "Epoch 300/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4368 - accuracy: 0.4455\n",
            "Epoch 301/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4346 - accuracy: 0.4455\n",
            "Epoch 302/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4328 - accuracy: 0.4458\n",
            "Epoch 303/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4322 - accuracy: 0.4448\n",
            "Epoch 304/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.4284 - accuracy: 0.4459\n",
            "Epoch 305/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4331 - accuracy: 0.4451\n",
            "Epoch 306/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4302 - accuracy: 0.4463\n",
            "Epoch 307/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4236 - accuracy: 0.4483\n",
            "Epoch 308/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4282 - accuracy: 0.4469\n",
            "Epoch 309/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4154 - accuracy: 0.4498\n",
            "Epoch 310/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4293 - accuracy: 0.4467\n",
            "Epoch 311/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4228 - accuracy: 0.4477\n",
            "Epoch 312/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4164 - accuracy: 0.4497\n",
            "Epoch 313/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4262 - accuracy: 0.4465\n",
            "Epoch 314/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4231 - accuracy: 0.4478\n",
            "Epoch 315/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4116 - accuracy: 0.4503\n",
            "Epoch 316/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4123 - accuracy: 0.4503\n",
            "Epoch 317/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4078 - accuracy: 0.4511\n",
            "Epoch 318/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4103 - accuracy: 0.4499\n",
            "Epoch 319/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4137 - accuracy: 0.4501\n",
            "Epoch 320/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4122 - accuracy: 0.4496\n",
            "Epoch 321/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4071 - accuracy: 0.4514\n",
            "Epoch 322/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4061 - accuracy: 0.4516\n",
            "Epoch 323/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4058 - accuracy: 0.4501\n",
            "Epoch 324/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4064 - accuracy: 0.4514\n",
            "Epoch 325/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4044 - accuracy: 0.4512\n",
            "Epoch 326/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3996 - accuracy: 0.4517\n",
            "Epoch 327/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4007 - accuracy: 0.4530\n",
            "Epoch 328/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.4023 - accuracy: 0.4512\n",
            "Epoch 329/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3963 - accuracy: 0.4535\n",
            "Epoch 330/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3966 - accuracy: 0.4522\n",
            "Epoch 331/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3901 - accuracy: 0.4541\n",
            "Epoch 332/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3997 - accuracy: 0.4511\n",
            "Epoch 333/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3980 - accuracy: 0.4521\n",
            "Epoch 334/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3948 - accuracy: 0.4527\n",
            "Epoch 335/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3890 - accuracy: 0.4543\n",
            "Epoch 336/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3887 - accuracy: 0.4529\n",
            "Epoch 337/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3886 - accuracy: 0.4540\n",
            "Epoch 338/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3856 - accuracy: 0.4535\n",
            "Epoch 339/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3871 - accuracy: 0.4546\n",
            "Epoch 340/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3864 - accuracy: 0.4544\n",
            "Epoch 341/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3782 - accuracy: 0.4566\n",
            "Epoch 342/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3810 - accuracy: 0.4555\n",
            "Epoch 343/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3792 - accuracy: 0.4546\n",
            "Epoch 344/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3775 - accuracy: 0.4568\n",
            "Epoch 345/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3799 - accuracy: 0.4552\n",
            "Epoch 346/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3730 - accuracy: 0.4575\n",
            "Epoch 347/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3700 - accuracy: 0.4574\n",
            "Epoch 348/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3797 - accuracy: 0.4557\n",
            "Epoch 349/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3763 - accuracy: 0.4556\n",
            "Epoch 350/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3698 - accuracy: 0.4588\n",
            "Epoch 351/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3806 - accuracy: 0.4549\n",
            "Epoch 352/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3752 - accuracy: 0.4566\n",
            "Epoch 353/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3612 - accuracy: 0.4594\n",
            "Epoch 354/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3701 - accuracy: 0.4572\n",
            "Epoch 355/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3682 - accuracy: 0.4577\n",
            "Epoch 356/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3700 - accuracy: 0.4566\n",
            "Epoch 357/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3626 - accuracy: 0.4594\n",
            "Epoch 358/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3656 - accuracy: 0.4585\n",
            "Epoch 359/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3634 - accuracy: 0.4584\n",
            "Epoch 360/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3605 - accuracy: 0.4594\n",
            "Epoch 361/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3545 - accuracy: 0.4604\n",
            "Epoch 362/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3643 - accuracy: 0.4570\n",
            "Epoch 363/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3516 - accuracy: 0.4615\n",
            "Epoch 364/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3580 - accuracy: 0.4595\n",
            "Epoch 365/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3610 - accuracy: 0.4585\n",
            "Epoch 366/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3504 - accuracy: 0.4610\n",
            "Epoch 367/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3466 - accuracy: 0.4627\n",
            "Epoch 368/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3509 - accuracy: 0.4616\n",
            "Epoch 369/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3578 - accuracy: 0.4600\n",
            "Epoch 370/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3563 - accuracy: 0.4601\n",
            "Epoch 371/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3434 - accuracy: 0.4613\n",
            "Epoch 372/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3477 - accuracy: 0.4619\n",
            "Epoch 373/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3470 - accuracy: 0.4620\n",
            "Epoch 374/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3474 - accuracy: 0.4614\n",
            "Epoch 375/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3487 - accuracy: 0.4605\n",
            "Epoch 376/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3406 - accuracy: 0.4633\n",
            "Epoch 377/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3432 - accuracy: 0.4621\n",
            "Epoch 378/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3410 - accuracy: 0.4632\n",
            "Epoch 379/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3378 - accuracy: 0.4636\n",
            "Epoch 380/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3359 - accuracy: 0.4637\n",
            "Epoch 381/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3369 - accuracy: 0.4643\n",
            "Epoch 382/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3417 - accuracy: 0.4623\n",
            "Epoch 383/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3375 - accuracy: 0.4637\n",
            "Epoch 384/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3331 - accuracy: 0.4643\n",
            "Epoch 385/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3405 - accuracy: 0.4630\n",
            "Epoch 386/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3323 - accuracy: 0.4645\n",
            "Epoch 387/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3289 - accuracy: 0.4647\n",
            "Epoch 388/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3292 - accuracy: 0.4651\n",
            "Epoch 389/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3306 - accuracy: 0.4639\n",
            "Epoch 390/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3349 - accuracy: 0.4639\n",
            "Epoch 391/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3354 - accuracy: 0.4637\n",
            "Epoch 392/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.3178 - accuracy: 0.4678\n",
            "Epoch 393/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.3249 - accuracy: 0.4668\n",
            "Epoch 394/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.3238 - accuracy: 0.4661\n",
            "Epoch 395/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.3283 - accuracy: 0.4649\n",
            "Epoch 396/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3246 - accuracy: 0.4659\n",
            "Epoch 397/400\n",
            "887/887 [==============================] - 10s 12ms/step - loss: 2.3172 - accuracy: 0.4679\n",
            "Epoch 398/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.3278 - accuracy: 0.4656\n",
            "Epoch 399/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.3213 - accuracy: 0.4659\n",
            "Epoch 400/400\n",
            "887/887 [==============================] - 11s 12ms/step - loss: 2.3176 - accuracy: 0.4678\n"
          ]
        }
      ],
      "source": [
        "#igone this part as it used for re training the already trained model bu the performance was not increasing\n",
        "history= model.fit(x, y, batch_size=64, epochs=100,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PH0qodqVn6ph",
      "metadata": {
        "id": "PH0qodqVn6ph"
      },
      "outputs": [],
      "source": [
        "model=load_model('/content/gdrive/MyDrive/model_text_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cacba0c4-c444-4b62-8ac2-fe02ce5158fa",
      "metadata": {
        "id": "cacba0c4-c444-4b62-8ac2-fe02ce5158fa"
      },
      "outputs": [],
      "source": [
        "# Saving the trained model\n",
        "model.save('/content/gdrive/MyDrive/model_text_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de7aa77e-fbba-4c47-a836-d0a8efd0ec6e",
      "metadata": {
        "id": "de7aa77e-fbba-4c47-a836-d0a8efd0ec6e"
      },
      "outputs": [],
      "source": [
        "# saving tokeniser\n",
        "dump(tokenizer, open('/content/gdrive/MyDrive/science_fiction/tokenizer.pkl', 'wb')) #provide the location to save the tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b01dcb7-58bd-4dd5-bc16-c90745c07c9e",
      "metadata": {
        "id": "6b01dcb7-58bd-4dd5-bc16-c90745c07c9e"
      },
      "source": [
        "### Testing on Unknown text/ words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "N3Kwrsc3-qUZ",
      "metadata": {
        "id": "N3Kwrsc3-qUZ"
      },
      "outputs": [],
      "source": [
        "model_load=load_model('/content/gdrive/MyDrive/210409183_textprediction_model.h5')#loadig model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ba7bfa-c79f-42d1-8ad8-873b54d6aee0",
      "metadata": {
        "id": "56ba7bfa-c79f-42d1-8ad8-873b54d6aee0"
      },
      "outputs": [],
      "source": [
        "# Loading the model and tokeniser\n",
        "#model = load_model(\"/content/gdrive/MyDrive/science_fiction/model_1.h5\")\n",
        "tokenizer = load(open(\"/content/gdrive/MyDrive/science_fiction/tokenizer.pkl\", 'rb')) #loading tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c9e21c94-76e6-4bf3-afd5-648f12f3232a",
      "metadata": {
        "id": "c9e21c94-76e6-4bf3-afd5-648f12f3232a"
      },
      "outputs": [],
      "source": [
        "# test words\n",
        "test_text= '''the people are scared because\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e0d4730b-25c9-4b62-afa4-f6be804f3d11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0d4730b-25c9-4b62-afa4-f6be804f3d11",
        "outputId": "b2352e1d-ad6f-41d5-d212-38358a575695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the people are scared because\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "61716691-5b5e-496c-8470-462b1fee24b1",
      "metadata": {
        "id": "61716691-5b5e-496c-8470-462b1fee24b1"
      },
      "outputs": [],
      "source": [
        "# Cleaning text\n",
        "def clean_text_1(text):\n",
        "    # replace '--' with a space\n",
        "    text= text.replace('--', ' ')\n",
        "    #splitting into words by space\n",
        "    tokens= text.split()\n",
        "    # punctuations removal\n",
        "    tokens= [token.translate(str.maketrans('', '', string.punctuation)) for token in tokens]\n",
        "    #removing non-aplhabetic tokens\n",
        "    tokens= [word for word in tokens if word.isalpha()]\n",
        "    # lower-case\n",
        "    tokens= [word.lower() for word in tokens]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9e2b84b9-be84-4106-b098-419c623c18ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e2b84b9-be84-4106-b098-419c623c18ea",
        "outputId": "bac2d823-bfc5-47e7-fdd4-8aa9602c194c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "tokens_test= clean_text_1(test_text)\n",
        "print(len(tokens_test))\n",
        "print(len(set(tokens_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c2adace6-287c-4b06-a03a-840dc2f4100c",
      "metadata": {
        "id": "c2adace6-287c-4b06-a03a-840dc2f4100c"
      },
      "outputs": [],
      "source": [
        "# generating text\n",
        "\n",
        "def generate_sequence(model, tokenizer, sequence_length, seed_text, n_words):\n",
        "    out = list()\n",
        "    in_text = seed_text\n",
        "    # generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "        # encode the text as integer\n",
        "        encoded_text = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        # truncate sequences to a fixed length\n",
        "        encoded_text = pad_sequences([encoded_text], maxlen=sequence_length, truncating='pre')\n",
        "        # predict probabilities for each word\n",
        "        yhat = np.argmax(model.predict(encoded_text, verbose=0), axis= -1)\n",
        "        # map predicted word index to word\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == yhat:\n",
        "                out_word = word\n",
        "                break\n",
        "        # append to input\n",
        "        in_text += ' ' + out_word\n",
        "        out.append(out_word)\n",
        "    return ' '.join(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45d98fb1-6025-40e9-861e-f3d6df6e842e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45d98fb1-6025-40e9-861e-f3d6df6e842e",
        "outputId": "04a3478d-65c1-4581-fc75-d3a69f998a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "breakers limbs black alien locality happened strictly racing might\n"
          ]
        }
      ],
      "source": [
        "# generate new text\n",
        "sequence_length = 10\n",
        "text_generated = generate_sequence(model_load, tokenizer, sequence_length, tokens_test, 9)\n",
        "print(text_generated)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
